{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Obtaining dependency information for tensorflow from https://files.pythonhosted.org/packages/85/15/cf99a373812d37f8ae99752a34a9f5f690d820ceb5b302e922705bc18944/tensorflow-2.15.0-cp311-cp311-macosx_12_0_arm64.whl.metadata\n",
      "  Downloading tensorflow-2.15.0-cp311-cp311-macosx_12_0_arm64.whl.metadata (3.6 kB)\n",
      "Collecting tensorflow-macos==2.15.0 (from tensorflow)\n",
      "  Obtaining dependency information for tensorflow-macos==2.15.0 from https://files.pythonhosted.org/packages/eb/9f/0759e2fea4a3c48f070b64811c2c57036b46353ba87263afc810b8f4188a/tensorflow_macos-2.15.0-cp311-cp311-macosx_12_0_arm64.whl.metadata\n",
      "  Downloading tensorflow_macos-2.15.0-cp311-cp311-macosx_12_0_arm64.whl.metadata (4.2 kB)\n",
      "Collecting absl-py>=1.0.0 (from tensorflow-macos==2.15.0->tensorflow)\n",
      "  Obtaining dependency information for absl-py>=1.0.0 from https://files.pythonhosted.org/packages/01/e4/dc0a1dcc4e74e08d7abedab278c795eef54a224363bb18f5692f416d834f/absl_py-2.0.0-py3-none-any.whl.metadata\n",
      "  Downloading absl_py-2.0.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting astunparse>=1.6.0 (from tensorflow-macos==2.15.0->tensorflow)\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting flatbuffers>=23.5.26 (from tensorflow-macos==2.15.0->tensorflow)\n",
      "  Obtaining dependency information for flatbuffers>=23.5.26 from https://files.pythonhosted.org/packages/6f/12/d5c79ee252793ffe845d58a913197bfa02ae9a0b5c9bc3dc4b58d477b9e7/flatbuffers-23.5.26-py2.py3-none-any.whl.metadata\n",
      "  Downloading flatbuffers-23.5.26-py2.py3-none-any.whl.metadata (850 bytes)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 (from tensorflow-macos==2.15.0->tensorflow)\n",
      "  Downloading gast-0.5.4-py3-none-any.whl (19 kB)\n",
      "Collecting google-pasta>=0.1.1 (from tensorflow-macos==2.15.0->tensorflow)\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.5/57.5 kB\u001b[0m \u001b[31m811.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:--:--\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: h5py>=2.9.0 in /Users/krystynapieterson/anaconda3/lib/python3.11/site-packages (from tensorflow-macos==2.15.0->tensorflow) (3.7.0)\n",
      "Collecting libclang>=13.0.0 (from tensorflow-macos==2.15.0->tensorflow)\n",
      "  Obtaining dependency information for libclang>=13.0.0 from https://files.pythonhosted.org/packages/32/1f/981809b77b71972beec34b3ff5422c1b1f7e519daac7b3cbd055c05ba2cf/libclang-16.0.6-py2.py3-none-macosx_11_0_arm64.whl.metadata\n",
      "  Downloading libclang-16.0.6-py2.py3-none-macosx_11_0_arm64.whl.metadata (5.2 kB)\n",
      "Collecting ml-dtypes~=0.2.0 (from tensorflow-macos==2.15.0->tensorflow)\n",
      "  Obtaining dependency information for ml-dtypes~=0.2.0 from https://files.pythonhosted.org/packages/15/da/43bee505963da0c730ee50e951c604bfdb90d4cccc9c0044c946b10e68a7/ml_dtypes-0.2.0-cp311-cp311-macosx_10_9_universal2.whl.metadata\n",
      "  Downloading ml_dtypes-0.2.0-cp311-cp311-macosx_10_9_universal2.whl.metadata (20 kB)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /Users/krystynapieterson/anaconda3/lib/python3.11/site-packages (from tensorflow-macos==2.15.0->tensorflow) (1.24.3)\n",
      "Collecting opt-einsum>=2.3.2 (from tensorflow-macos==2.15.0->tensorflow)\n",
      "  Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.5/65.5 kB\u001b[0m \u001b[31m499.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: packaging in /Users/krystynapieterson/anaconda3/lib/python3.11/site-packages (from tensorflow-macos==2.15.0->tensorflow) (23.0)\n",
      "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 (from tensorflow-macos==2.15.0->tensorflow)\n",
      "  Obtaining dependency information for protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 from https://files.pythonhosted.org/packages/e6/db/7b2edc72807d45d72f9db42f3eb86ddaf37f9e55d923159b1dbfc9d835bc/protobuf-4.25.1-cp37-abi3-macosx_10_9_universal2.whl.metadata\n",
      "  Downloading protobuf-4.25.1-cp37-abi3-macosx_10_9_universal2.whl.metadata (541 bytes)\n",
      "Requirement already satisfied: setuptools in /Users/krystynapieterson/anaconda3/lib/python3.11/site-packages (from tensorflow-macos==2.15.0->tensorflow) (68.0.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /Users/krystynapieterson/anaconda3/lib/python3.11/site-packages (from tensorflow-macos==2.15.0->tensorflow) (1.16.0)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow-macos==2.15.0->tensorflow)\n",
      "  Downloading termcolor-2.3.0-py3-none-any.whl (6.9 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /Users/krystynapieterson/anaconda3/lib/python3.11/site-packages (from tensorflow-macos==2.15.0->tensorflow) (4.7.1)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /Users/krystynapieterson/anaconda3/lib/python3.11/site-packages (from tensorflow-macos==2.15.0->tensorflow) (1.14.1)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1 (from tensorflow-macos==2.15.0->tensorflow)\n",
      "  Obtaining dependency information for tensorflow-io-gcs-filesystem>=0.23.1 from https://files.pythonhosted.org/packages/5b/e9/1444afc87596a90066704cc46ed661a4e7b348eec03a3fc2ca10ab917254/tensorflow_io_gcs_filesystem-0.34.0-cp311-cp311-macosx_12_0_arm64.whl.metadata\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.34.0-cp311-cp311-macosx_12_0_arm64.whl.metadata (14 kB)\n",
      "Collecting grpcio<2.0,>=1.24.3 (from tensorflow-macos==2.15.0->tensorflow)\n",
      "  Obtaining dependency information for grpcio<2.0,>=1.24.3 from https://files.pythonhosted.org/packages/92/93/3cbc00a269b46277ff26355074a8315eeb4c87240c27d6f7efeabe818fd9/grpcio-1.59.3-cp311-cp311-macosx_10_10_universal2.whl.metadata\n",
      "  Downloading grpcio-1.59.3-cp311-cp311-macosx_10_10_universal2.whl.metadata (4.0 kB)\n",
      "Collecting tensorboard<2.16,>=2.15 (from tensorflow-macos==2.15.0->tensorflow)\n",
      "  Obtaining dependency information for tensorboard<2.16,>=2.15 from https://files.pythonhosted.org/packages/6e/0c/1059a6682cf2cc1fcc0d5327837b5672fe4f5574255fa5430d0a8ceb75e9/tensorboard-2.15.1-py3-none-any.whl.metadata\n",
      "  Downloading tensorboard-2.15.1-py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting tensorflow-estimator<2.16,>=2.15.0 (from tensorflow-macos==2.15.0->tensorflow)\n",
      "  Obtaining dependency information for tensorflow-estimator<2.16,>=2.15.0 from https://files.pythonhosted.org/packages/b6/c8/2f823c8958d5342eafc6dd3e922f0cc4fcf8c2e0460284cc462dae3b60a0/tensorflow_estimator-2.15.0-py2.py3-none-any.whl.metadata\n",
      "  Downloading tensorflow_estimator-2.15.0-py2.py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting keras<2.16,>=2.15.0 (from tensorflow-macos==2.15.0->tensorflow)\n",
      "  Obtaining dependency information for keras<2.16,>=2.15.0 from https://files.pythonhosted.org/packages/fc/a7/0d4490de967a67f68a538cc9cdb259bff971c4b5787f7765dc7c8f118f71/keras-2.15.0-py3-none-any.whl.metadata\n",
      "  Downloading keras-2.15.0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /Users/krystynapieterson/anaconda3/lib/python3.11/site-packages (from astunparse>=1.6.0->tensorflow-macos==2.15.0->tensorflow) (0.38.4)\n",
      "Collecting google-auth<3,>=1.6.3 (from tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow)\n",
      "  Obtaining dependency information for google-auth<3,>=1.6.3 from https://files.pythonhosted.org/packages/86/a7/75911c13a242735d5aeaca6a272da380335ff4ba5f26d6b2ae20ff682d13/google_auth-2.23.4-py2.py3-none-any.whl.metadata\n",
      "  Downloading google_auth-2.23.4-py2.py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting google-auth-oauthlib<2,>=0.5 (from tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow)\n",
      "  Obtaining dependency information for google-auth-oauthlib<2,>=0.5 from https://files.pythonhosted.org/packages/ce/33/a907b4b67245647746dde8d61e1643ef5d210c88e090d491efd89eff9f95/google_auth_oauthlib-1.1.0-py2.py3-none-any.whl.metadata\n",
      "  Downloading google_auth_oauthlib-1.1.0-py2.py3-none-any.whl.metadata (2.7 kB)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Users/krystynapieterson/anaconda3/lib/python3.11/site-packages (from tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow) (3.4.1)\n",
      "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 (from tensorflow-macos==2.15.0->tensorflow)\n",
      "  Obtaining dependency information for protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 from https://files.pythonhosted.org/packages/cb/d3/a164038605494d49acc4f9cda1c0bc200b96382c53edd561387263bb181d/protobuf-4.23.4-cp37-abi3-macosx_10_9_universal2.whl.metadata\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Downloading protobuf-4.23.4-cp37-abi3-macosx_10_9_universal2.whl.metadata (540 bytes)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /Users/krystynapieterson/anaconda3/lib/python3.11/site-packages (from tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow) (2.31.0)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow)\n",
      "  Obtaining dependency information for tensorboard-data-server<0.8.0,>=0.7.0 from https://files.pythonhosted.org/packages/7a/13/e503968fefabd4c6b2650af21e110aa8466fe21432cd7c43a84577a89438/tensorboard_data_server-0.7.2-py3-none-any.whl.metadata\n",
      "  Downloading tensorboard_data_server-0.7.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /Users/krystynapieterson/anaconda3/lib/python3.11/site-packages (from tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow) (2.2.3)\n",
      "Collecting cachetools<6.0,>=2.0.0 (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow)\n",
      "  Obtaining dependency information for cachetools<6.0,>=2.0.0 from https://files.pythonhosted.org/packages/a2/91/2d843adb9fbd911e0da45fbf6f18ca89d07a087c3daa23e955584f90ebf4/cachetools-5.3.2-py3-none-any.whl.metadata\n",
      "  Downloading cachetools-5.3.2-py3-none-any.whl.metadata (5.2 kB)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/krystynapieterson/anaconda3/lib/python3.11/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow) (0.2.8)\n",
      "Collecting rsa<5,>=3.1.4 (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow)\n",
      "  Downloading rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Collecting requests-oauthlib>=0.7.0 (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow)\n",
      "  Downloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/krystynapieterson/anaconda3/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/krystynapieterson/anaconda3/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/krystynapieterson/anaconda3/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/krystynapieterson/anaconda3/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow) (2023.7.22)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /Users/krystynapieterson/anaconda3/lib/python3.11/site-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow) (2.1.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /Users/krystynapieterson/anaconda3/lib/python3.11/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow) (0.4.8)\n",
      "Collecting oauthlib>=3.0.0 (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow)\n",
      "  Downloading oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m151.7/151.7 kB\u001b[0m \u001b[31m512.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading tensorflow-2.15.0-cp311-cp311-macosx_12_0_arm64.whl (2.1 kB)\n",
      "Downloading tensorflow_macos-2.15.0-cp311-cp311-macosx_12_0_arm64.whl (208.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m208.8/208.8 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:02\u001b[0mm\n",
      "\u001b[?25hDownloading absl_py-2.0.0-py3-none-any.whl (130 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading flatbuffers-23.5.26-py2.py3-none-any.whl (26 kB)\n",
      "Downloading grpcio-1.59.3-cp311-cp311-macosx_10_10_universal2.whl (9.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.6/9.6 MB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading keras-2.15.0-py3-none-any.whl (1.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading libclang-16.0.6-py2.py3-none-macosx_11_0_arm64.whl (20.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.6/20.6 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading ml_dtypes-0.2.0-cp311-cp311-macosx_10_9_universal2.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading tensorboard-2.15.1-py3-none-any.whl (5.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading protobuf-4.23.4-cp37-abi3-macosx_10_9_universal2.whl (400 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m400.3/400.3 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading tensorflow_estimator-2.15.0-py2.py3-none-any.whl (441 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m442.0/442.0 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading tensorflow_io_gcs_filesystem-0.34.0-cp311-cp311-macosx_12_0_arm64.whl (1.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading google_auth-2.23.4-py2.py3-none-any.whl (183 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.3/183.3 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading google_auth_oauthlib-1.1.0-py2.py3-none-any.whl (19 kB)\n",
      "Downloading tensorboard_data_server-0.7.2-py3-none-any.whl (2.4 kB)\n",
      "Downloading cachetools-5.3.2-py3-none-any.whl (9.3 kB)\n",
      "Installing collected packages: libclang, flatbuffers, termcolor, tensorflow-io-gcs-filesystem, tensorflow-estimator, tensorboard-data-server, rsa, protobuf, opt-einsum, oauthlib, ml-dtypes, keras, grpcio, google-pasta, gast, cachetools, astunparse, absl-py, requests-oauthlib, google-auth, google-auth-oauthlib, tensorboard, tensorflow-macos, tensorflow\n",
      "Successfully installed absl-py-2.0.0 astunparse-1.6.3 cachetools-5.3.2 flatbuffers-23.5.26 gast-0.5.4 google-auth-2.23.4 google-auth-oauthlib-1.1.0 google-pasta-0.2.0 grpcio-1.59.3 keras-2.15.0 libclang-16.0.6 ml-dtypes-0.2.0 oauthlib-3.2.2 opt-einsum-3.3.0 protobuf-4.23.4 requests-oauthlib-1.3.1 rsa-4.9 tensorboard-2.15.1 tensorboard-data-server-0.7.2 tensorflow-2.15.0 tensorflow-estimator-2.15.0 tensorflow-io-gcs-filesystem-0.34.0 tensorflow-macos-2.15.0 termcolor-2.3.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Customer ID           object\n",
       "Gender                object\n",
       "Senior Citizen         int64\n",
       "Partner               object\n",
       "Dependents            object\n",
       "tenure                 int64\n",
       "Phone Service         object\n",
       "Multiple Lines        object\n",
       "Internet Service      object\n",
       "Online Security       object\n",
       "Online Backup         object\n",
       "Device Protection     object\n",
       "Tech Support          object\n",
       "Streaming TV          object\n",
       "Streaming Movies      object\n",
       "Contract              object\n",
       "Paperless Billing     object\n",
       "Payment Method        object\n",
       "Monthly Charges      float64\n",
       "Total Charges         object\n",
       "Churn                 object\n",
       "dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Churn.csv')\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Senior Citizen</th>\n",
       "      <th>tenure</th>\n",
       "      <th>Monthly Charges</th>\n",
       "      <th>Gender_Female</th>\n",
       "      <th>Gender_Male</th>\n",
       "      <th>Partner_No</th>\n",
       "      <th>Partner_Yes</th>\n",
       "      <th>Dependents_No</th>\n",
       "      <th>Dependents_Yes</th>\n",
       "      <th>Phone Service_No</th>\n",
       "      <th>...</th>\n",
       "      <th>Total Charges_995.35</th>\n",
       "      <th>Total Charges_996.45</th>\n",
       "      <th>Total Charges_996.85</th>\n",
       "      <th>Total Charges_996.95</th>\n",
       "      <th>Total Charges_997.65</th>\n",
       "      <th>Total Charges_997.75</th>\n",
       "      <th>Total Charges_998.1</th>\n",
       "      <th>Total Charges_999.45</th>\n",
       "      <th>Total Charges_999.8</th>\n",
       "      <th>Total Charges_999.9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>29.85</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>29.85</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>56.95</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>53.85</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>42.30</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 6575 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Senior Citizen  tenure  Monthly Charges  Gender_Female  Gender_Male  \\\n",
       "0               0       1            29.85              1            0   \n",
       "1               0       1            29.85              1            0   \n",
       "2               0      34            56.95              0            1   \n",
       "3               0       2            53.85              0            1   \n",
       "4               0      45            42.30              0            1   \n",
       "\n",
       "   Partner_No  Partner_Yes  Dependents_No  Dependents_Yes  Phone Service_No  \\\n",
       "0           0            1              1               0                 1   \n",
       "1           0            1              1               0                 1   \n",
       "2           1            0              1               0                 0   \n",
       "3           1            0              1               0                 0   \n",
       "4           1            0              1               0                 1   \n",
       "\n",
       "   ...  Total Charges_995.35  Total Charges_996.45  Total Charges_996.85  \\\n",
       "0  ...                     0                     0                     0   \n",
       "1  ...                     0                     0                     0   \n",
       "2  ...                     0                     0                     0   \n",
       "3  ...                     0                     0                     0   \n",
       "4  ...                     0                     0                     0   \n",
       "\n",
       "   Total Charges_996.95  Total Charges_997.65  Total Charges_997.75  \\\n",
       "0                     0                     0                     0   \n",
       "1                     0                     0                     0   \n",
       "2                     0                     0                     0   \n",
       "3                     0                     0                     0   \n",
       "4                     0                     0                     0   \n",
       "\n",
       "   Total Charges_998.1  Total Charges_999.45  Total Charges_999.8  \\\n",
       "0                    0                     0                    0   \n",
       "1                    0                     0                    0   \n",
       "2                    0                     0                    0   \n",
       "3                    0                     0                    0   \n",
       "4                    0                     0                    0   \n",
       "\n",
       "   Total Charges_999.9  \n",
       "0                    0  \n",
       "1                    0  \n",
       "2                    0  \n",
       "3                    0  \n",
       "4                    0  \n",
       "\n",
       "[5 rows x 6575 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = pd.get_dummies(df.drop(['Churn', 'Customer ID'], axis=1))\n",
    "y = df['Churn'].apply(lambda x: 1 if x=='Yes' else 0)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4979    1\n",
       "4233    1\n",
       "4184    0\n",
       "6457    0\n",
       "1528    0\n",
       "Name: Churn, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Build and Compile Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(units=32, activation='relu', input_dim=len(X_train.columns)))\n",
    "model.add(Dense(units=64, activation='relu'))\n",
    "model.add(Dense(units=1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='sgd', metrics='accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Fit, Predict and Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/400\n",
      "177/177 [==============================] - 0s 694us/step - loss: 0.4152 - accuracy: 0.8055\n",
      "Epoch 2/400\n",
      "177/177 [==============================] - 0s 641us/step - loss: 0.4145 - accuracy: 0.8018\n",
      "Epoch 3/400\n",
      "177/177 [==============================] - 0s 638us/step - loss: 0.4155 - accuracy: 0.8039\n",
      "Epoch 4/400\n",
      "177/177 [==============================] - 0s 658us/step - loss: 0.4169 - accuracy: 0.8016\n",
      "Epoch 5/400\n",
      "177/177 [==============================] - 0s 641us/step - loss: 0.4155 - accuracy: 0.8000\n",
      "Epoch 6/400\n",
      "177/177 [==============================] - 0s 647us/step - loss: 0.4161 - accuracy: 0.8032\n",
      "Epoch 7/400\n",
      "177/177 [==============================] - 0s 647us/step - loss: 0.4164 - accuracy: 0.8025\n",
      "Epoch 8/400\n",
      "177/177 [==============================] - 0s 657us/step - loss: 0.4127 - accuracy: 0.8037\n",
      "Epoch 9/400\n",
      "177/177 [==============================] - 0s 663us/step - loss: 0.4143 - accuracy: 0.8012\n",
      "Epoch 10/400\n",
      "177/177 [==============================] - 0s 661us/step - loss: 0.4122 - accuracy: 0.8057\n",
      "Epoch 11/400\n",
      "177/177 [==============================] - 0s 634us/step - loss: 0.4144 - accuracy: 0.8007\n",
      "Epoch 12/400\n",
      "177/177 [==============================] - 0s 639us/step - loss: 0.4149 - accuracy: 0.8039\n",
      "Epoch 13/400\n",
      "177/177 [==============================] - 0s 645us/step - loss: 0.4144 - accuracy: 0.8046\n",
      "Epoch 14/400\n",
      "177/177 [==============================] - 0s 641us/step - loss: 0.4151 - accuracy: 0.8023\n",
      "Epoch 15/400\n",
      "177/177 [==============================] - 0s 641us/step - loss: 0.4128 - accuracy: 0.8032\n",
      "Epoch 16/400\n",
      "177/177 [==============================] - 0s 640us/step - loss: 0.4132 - accuracy: 0.8083\n",
      "Epoch 17/400\n",
      "177/177 [==============================] - 0s 620us/step - loss: 0.4137 - accuracy: 0.8041\n",
      "Epoch 18/400\n",
      "177/177 [==============================] - 0s 634us/step - loss: 0.4109 - accuracy: 0.8051\n",
      "Epoch 19/400\n",
      "177/177 [==============================] - 0s 636us/step - loss: 0.4119 - accuracy: 0.8057\n",
      "Epoch 20/400\n",
      "177/177 [==============================] - 0s 639us/step - loss: 0.4143 - accuracy: 0.8037\n",
      "Epoch 21/400\n",
      "177/177 [==============================] - 0s 643us/step - loss: 0.4123 - accuracy: 0.8069\n",
      "Epoch 22/400\n",
      "177/177 [==============================] - 0s 651us/step - loss: 0.4123 - accuracy: 0.8071\n",
      "Epoch 23/400\n",
      "177/177 [==============================] - 0s 653us/step - loss: 0.4143 - accuracy: 0.8043\n",
      "Epoch 24/400\n",
      "177/177 [==============================] - 0s 640us/step - loss: 0.4139 - accuracy: 0.8005\n",
      "Epoch 25/400\n",
      "177/177 [==============================] - 0s 640us/step - loss: 0.4129 - accuracy: 0.8067\n",
      "Epoch 26/400\n",
      "177/177 [==============================] - 0s 617us/step - loss: 0.4146 - accuracy: 0.8011\n",
      "Epoch 27/400\n",
      "177/177 [==============================] - 0s 641us/step - loss: 0.4129 - accuracy: 0.8025\n",
      "Epoch 28/400\n",
      "177/177 [==============================] - 0s 636us/step - loss: 0.4142 - accuracy: 0.8021\n",
      "Epoch 29/400\n",
      "177/177 [==============================] - 0s 635us/step - loss: 0.4138 - accuracy: 0.8027\n",
      "Epoch 30/400\n",
      "177/177 [==============================] - 0s 669us/step - loss: 0.4255 - accuracy: 0.7979\n",
      "Epoch 31/400\n",
      "177/177 [==============================] - 0s 662us/step - loss: 0.4168 - accuracy: 0.8014\n",
      "Epoch 32/400\n",
      "177/177 [==============================] - 0s 705us/step - loss: 0.4130 - accuracy: 0.8048\n",
      "Epoch 33/400\n",
      "177/177 [==============================] - 0s 755us/step - loss: 0.4128 - accuracy: 0.8069\n",
      "Epoch 34/400\n",
      "177/177 [==============================] - 0s 706us/step - loss: 0.4145 - accuracy: 0.8048\n",
      "Epoch 35/400\n",
      "177/177 [==============================] - 0s 694us/step - loss: 0.4136 - accuracy: 0.8034\n",
      "Epoch 36/400\n",
      "177/177 [==============================] - 0s 706us/step - loss: 0.4112 - accuracy: 0.8055\n",
      "Epoch 37/400\n",
      "177/177 [==============================] - 0s 727us/step - loss: 0.4122 - accuracy: 0.8053\n",
      "Epoch 38/400\n",
      "177/177 [==============================] - 0s 647us/step - loss: 0.4140 - accuracy: 0.8009\n",
      "Epoch 39/400\n",
      "177/177 [==============================] - 0s 639us/step - loss: 0.4124 - accuracy: 0.8059\n",
      "Epoch 40/400\n",
      "177/177 [==============================] - 0s 638us/step - loss: 0.4116 - accuracy: 0.8057\n",
      "Epoch 41/400\n",
      "177/177 [==============================] - 0s 642us/step - loss: 0.4162 - accuracy: 0.8039\n",
      "Epoch 42/400\n",
      "177/177 [==============================] - 0s 636us/step - loss: 0.4128 - accuracy: 0.8030\n",
      "Epoch 43/400\n",
      "177/177 [==============================] - 0s 662us/step - loss: 0.4129 - accuracy: 0.8043\n",
      "Epoch 44/400\n",
      "177/177 [==============================] - 0s 637us/step - loss: 0.4125 - accuracy: 0.8099\n",
      "Epoch 45/400\n",
      "177/177 [==============================] - 0s 653us/step - loss: 0.4129 - accuracy: 0.8046\n",
      "Epoch 46/400\n",
      "177/177 [==============================] - 0s 642us/step - loss: 0.4123 - accuracy: 0.8066\n",
      "Epoch 47/400\n",
      "177/177 [==============================] - 0s 637us/step - loss: 0.4126 - accuracy: 0.8060\n",
      "Epoch 48/400\n",
      "177/177 [==============================] - 0s 660us/step - loss: 0.4118 - accuracy: 0.8051\n",
      "Epoch 49/400\n",
      "177/177 [==============================] - 0s 642us/step - loss: 0.4127 - accuracy: 0.8053\n",
      "Epoch 50/400\n",
      "177/177 [==============================] - 0s 642us/step - loss: 0.4166 - accuracy: 0.8041\n",
      "Epoch 51/400\n",
      "177/177 [==============================] - 0s 640us/step - loss: 0.4143 - accuracy: 0.8014\n",
      "Epoch 52/400\n",
      "177/177 [==============================] - 0s 645us/step - loss: 0.4123 - accuracy: 0.8057\n",
      "Epoch 53/400\n",
      "177/177 [==============================] - 0s 660us/step - loss: 0.4133 - accuracy: 0.8035\n",
      "Epoch 54/400\n",
      "177/177 [==============================] - 0s 650us/step - loss: 0.4146 - accuracy: 0.8046\n",
      "Epoch 55/400\n",
      "177/177 [==============================] - 0s 690us/step - loss: 0.4126 - accuracy: 0.8043\n",
      "Epoch 56/400\n",
      "177/177 [==============================] - 0s 677us/step - loss: 0.4132 - accuracy: 0.8012\n",
      "Epoch 57/400\n",
      "177/177 [==============================] - 0s 682us/step - loss: 0.4117 - accuracy: 0.8046\n",
      "Epoch 58/400\n",
      "177/177 [==============================] - 0s 643us/step - loss: 0.4100 - accuracy: 0.8069\n",
      "Epoch 59/400\n",
      "177/177 [==============================] - 0s 654us/step - loss: 0.4131 - accuracy: 0.8046\n",
      "Epoch 60/400\n",
      "177/177 [==============================] - 0s 663us/step - loss: 0.4131 - accuracy: 0.8064\n",
      "Epoch 61/400\n",
      "177/177 [==============================] - 0s 653us/step - loss: 0.4127 - accuracy: 0.8043\n",
      "Epoch 62/400\n",
      "177/177 [==============================] - 0s 657us/step - loss: 0.4108 - accuracy: 0.8053\n",
      "Epoch 63/400\n",
      "177/177 [==============================] - 0s 680us/step - loss: 0.4113 - accuracy: 0.8078\n",
      "Epoch 64/400\n",
      "177/177 [==============================] - 0s 661us/step - loss: 0.4135 - accuracy: 0.7996\n",
      "Epoch 65/400\n",
      "177/177 [==============================] - 0s 643us/step - loss: 0.4107 - accuracy: 0.8060\n",
      "Epoch 66/400\n",
      "177/177 [==============================] - 0s 642us/step - loss: 0.4107 - accuracy: 0.8037\n",
      "Epoch 67/400\n",
      "177/177 [==============================] - 0s 648us/step - loss: 0.4120 - accuracy: 0.8059\n",
      "Epoch 68/400\n",
      "177/177 [==============================] - 0s 641us/step - loss: 0.4149 - accuracy: 0.8055\n",
      "Epoch 69/400\n",
      "177/177 [==============================] - 0s 650us/step - loss: 0.4115 - accuracy: 0.8048\n",
      "Epoch 70/400\n",
      "177/177 [==============================] - 0s 644us/step - loss: 0.4169 - accuracy: 0.8057\n",
      "Epoch 71/400\n",
      "177/177 [==============================] - 0s 631us/step - loss: 0.4106 - accuracy: 0.8035\n",
      "Epoch 72/400\n",
      "177/177 [==============================] - 0s 647us/step - loss: 0.4094 - accuracy: 0.8062\n",
      "Epoch 73/400\n",
      "177/177 [==============================] - 0s 657us/step - loss: 0.4105 - accuracy: 0.8075\n",
      "Epoch 74/400\n",
      "177/177 [==============================] - 0s 648us/step - loss: 0.4108 - accuracy: 0.8060\n",
      "Epoch 75/400\n",
      "177/177 [==============================] - 0s 641us/step - loss: 0.4109 - accuracy: 0.8014\n",
      "Epoch 76/400\n",
      "177/177 [==============================] - 0s 660us/step - loss: 0.4122 - accuracy: 0.8055\n",
      "Epoch 77/400\n",
      "177/177 [==============================] - 0s 639us/step - loss: 0.4161 - accuracy: 0.8009\n",
      "Epoch 78/400\n",
      "177/177 [==============================] - 0s 652us/step - loss: 0.4115 - accuracy: 0.8055\n",
      "Epoch 79/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "177/177 [==============================] - 0s 650us/step - loss: 0.4123 - accuracy: 0.8046\n",
      "Epoch 80/400\n",
      "177/177 [==============================] - 0s 631us/step - loss: 0.4133 - accuracy: 0.8057\n",
      "Epoch 81/400\n",
      "177/177 [==============================] - 0s 647us/step - loss: 0.4117 - accuracy: 0.8066\n",
      "Epoch 82/400\n",
      "177/177 [==============================] - 0s 643us/step - loss: 0.4114 - accuracy: 0.8064\n",
      "Epoch 83/400\n",
      "177/177 [==============================] - 0s 640us/step - loss: 0.4108 - accuracy: 0.8039\n",
      "Epoch 84/400\n",
      "177/177 [==============================] - 0s 651us/step - loss: 0.4096 - accuracy: 0.8083\n",
      "Epoch 85/400\n",
      "177/177 [==============================] - 0s 645us/step - loss: 0.4121 - accuracy: 0.8046\n",
      "Epoch 86/400\n",
      "177/177 [==============================] - 0s 649us/step - loss: 0.4114 - accuracy: 0.8080\n",
      "Epoch 87/400\n",
      "177/177 [==============================] - 0s 652us/step - loss: 0.4087 - accuracy: 0.8048\n",
      "Epoch 88/400\n",
      "177/177 [==============================] - 0s 651us/step - loss: 0.4119 - accuracy: 0.8025\n",
      "Epoch 89/400\n",
      "177/177 [==============================] - 0s 636us/step - loss: 0.4131 - accuracy: 0.8044\n",
      "Epoch 90/400\n",
      "177/177 [==============================] - 0s 649us/step - loss: 0.4087 - accuracy: 0.8103\n",
      "Epoch 91/400\n",
      "177/177 [==============================] - 0s 645us/step - loss: 0.4100 - accuracy: 0.8091\n",
      "Epoch 92/400\n",
      "177/177 [==============================] - 0s 649us/step - loss: 0.4127 - accuracy: 0.8035\n",
      "Epoch 93/400\n",
      "177/177 [==============================] - 0s 647us/step - loss: 0.4091 - accuracy: 0.8062\n",
      "Epoch 94/400\n",
      "177/177 [==============================] - 0s 646us/step - loss: 0.4122 - accuracy: 0.8041\n",
      "Epoch 95/400\n",
      "177/177 [==============================] - 0s 643us/step - loss: 0.4105 - accuracy: 0.8099\n",
      "Epoch 96/400\n",
      "177/177 [==============================] - 0s 645us/step - loss: 0.4119 - accuracy: 0.8064\n",
      "Epoch 97/400\n",
      "177/177 [==============================] - 0s 643us/step - loss: 0.4092 - accuracy: 0.8067\n",
      "Epoch 98/400\n",
      "177/177 [==============================] - 0s 628us/step - loss: 0.4099 - accuracy: 0.8083\n",
      "Epoch 99/400\n",
      "177/177 [==============================] - 0s 640us/step - loss: 0.4094 - accuracy: 0.8076\n",
      "Epoch 100/400\n",
      "177/177 [==============================] - 0s 650us/step - loss: 0.4149 - accuracy: 0.8044\n",
      "Epoch 101/400\n",
      "177/177 [==============================] - 0s 644us/step - loss: 0.4117 - accuracy: 0.8043\n",
      "Epoch 102/400\n",
      "177/177 [==============================] - 0s 635us/step - loss: 0.4095 - accuracy: 0.8041\n",
      "Epoch 103/400\n",
      "177/177 [==============================] - 0s 639us/step - loss: 0.4118 - accuracy: 0.8060\n",
      "Epoch 104/400\n",
      "177/177 [==============================] - 0s 646us/step - loss: 0.4098 - accuracy: 0.8014\n",
      "Epoch 105/400\n",
      "177/177 [==============================] - 0s 648us/step - loss: 0.4124 - accuracy: 0.8053\n",
      "Epoch 106/400\n",
      "177/177 [==============================] - 0s 647us/step - loss: 0.4107 - accuracy: 0.8046\n",
      "Epoch 107/400\n",
      "177/177 [==============================] - 0s 636us/step - loss: 0.4103 - accuracy: 0.8059\n",
      "Epoch 108/400\n",
      "177/177 [==============================] - 0s 642us/step - loss: 0.4094 - accuracy: 0.8050\n",
      "Epoch 109/400\n",
      "177/177 [==============================] - 0s 642us/step - loss: 0.4105 - accuracy: 0.8059\n",
      "Epoch 110/400\n",
      "177/177 [==============================] - 0s 648us/step - loss: 0.4090 - accuracy: 0.8053\n",
      "Epoch 111/400\n",
      "177/177 [==============================] - 0s 644us/step - loss: 0.4115 - accuracy: 0.8059\n",
      "Epoch 112/400\n",
      "177/177 [==============================] - 0s 643us/step - loss: 0.4108 - accuracy: 0.8053\n",
      "Epoch 113/400\n",
      "177/177 [==============================] - 0s 649us/step - loss: 0.4102 - accuracy: 0.8064\n",
      "Epoch 114/400\n",
      "177/177 [==============================] - 0s 644us/step - loss: 0.4103 - accuracy: 0.8034\n",
      "Epoch 115/400\n",
      "177/177 [==============================] - 0s 640us/step - loss: 0.4102 - accuracy: 0.8082\n",
      "Epoch 116/400\n",
      "177/177 [==============================] - 0s 637us/step - loss: 0.4125 - accuracy: 0.8048\n",
      "Epoch 117/400\n",
      "177/177 [==============================] - 0s 640us/step - loss: 0.4109 - accuracy: 0.8046\n",
      "Epoch 118/400\n",
      "177/177 [==============================] - 0s 667us/step - loss: 0.4101 - accuracy: 0.8025\n",
      "Epoch 119/400\n",
      "177/177 [==============================] - 0s 644us/step - loss: 0.4115 - accuracy: 0.7993\n",
      "Epoch 120/400\n",
      "177/177 [==============================] - 0s 654us/step - loss: 0.4097 - accuracy: 0.8051\n",
      "Epoch 121/400\n",
      "177/177 [==============================] - 0s 643us/step - loss: 0.4109 - accuracy: 0.8032\n",
      "Epoch 122/400\n",
      "177/177 [==============================] - 0s 648us/step - loss: 0.4094 - accuracy: 0.8057\n",
      "Epoch 123/400\n",
      "177/177 [==============================] - 0s 641us/step - loss: 0.4077 - accuracy: 0.8087\n",
      "Epoch 124/400\n",
      "177/177 [==============================] - 0s 650us/step - loss: 0.4096 - accuracy: 0.8069\n",
      "Epoch 125/400\n",
      "177/177 [==============================] - 0s 637us/step - loss: 0.4093 - accuracy: 0.8023\n",
      "Epoch 126/400\n",
      "177/177 [==============================] - 0s 642us/step - loss: 0.4101 - accuracy: 0.8055\n",
      "Epoch 127/400\n",
      "177/177 [==============================] - 0s 641us/step - loss: 0.4096 - accuracy: 0.8064\n",
      "Epoch 128/400\n",
      "177/177 [==============================] - 0s 643us/step - loss: 0.4097 - accuracy: 0.8078\n",
      "Epoch 129/400\n",
      "177/177 [==============================] - 0s 644us/step - loss: 0.4066 - accuracy: 0.8089\n",
      "Epoch 130/400\n",
      "177/177 [==============================] - 0s 647us/step - loss: 0.4099 - accuracy: 0.8085\n",
      "Epoch 131/400\n",
      "177/177 [==============================] - 0s 643us/step - loss: 0.4098 - accuracy: 0.8066\n",
      "Epoch 132/400\n",
      "177/177 [==============================] - 0s 651us/step - loss: 0.4100 - accuracy: 0.8055\n",
      "Epoch 133/400\n",
      "177/177 [==============================] - 0s 642us/step - loss: 0.4119 - accuracy: 0.8057\n",
      "Epoch 134/400\n",
      "177/177 [==============================] - 0s 635us/step - loss: 0.4099 - accuracy: 0.8082\n",
      "Epoch 135/400\n",
      "177/177 [==============================] - 0s 639us/step - loss: 0.4088 - accuracy: 0.8044\n",
      "Epoch 136/400\n",
      "177/177 [==============================] - 0s 656us/step - loss: 0.4095 - accuracy: 0.8078\n",
      "Epoch 137/400\n",
      "177/177 [==============================] - 0s 642us/step - loss: 0.4086 - accuracy: 0.8062\n",
      "Epoch 138/400\n",
      "177/177 [==============================] - 0s 657us/step - loss: 0.4083 - accuracy: 0.8064\n",
      "Epoch 139/400\n",
      "177/177 [==============================] - 0s 651us/step - loss: 0.4100 - accuracy: 0.8030\n",
      "Epoch 140/400\n",
      "177/177 [==============================] - 0s 649us/step - loss: 0.4099 - accuracy: 0.8034\n",
      "Epoch 141/400\n",
      "177/177 [==============================] - 0s 649us/step - loss: 0.4095 - accuracy: 0.8069\n",
      "Epoch 142/400\n",
      "177/177 [==============================] - 0s 643us/step - loss: 0.4094 - accuracy: 0.8067\n",
      "Epoch 143/400\n",
      "177/177 [==============================] - 0s 640us/step - loss: 0.4095 - accuracy: 0.8060\n",
      "Epoch 144/400\n",
      "177/177 [==============================] - 0s 655us/step - loss: 0.4064 - accuracy: 0.8073\n",
      "Epoch 145/400\n",
      "177/177 [==============================] - 0s 646us/step - loss: 0.4088 - accuracy: 0.8037\n",
      "Epoch 146/400\n",
      "177/177 [==============================] - 0s 645us/step - loss: 0.4128 - accuracy: 0.8041\n",
      "Epoch 147/400\n",
      "177/177 [==============================] - 0s 651us/step - loss: 0.4095 - accuracy: 0.8041\n",
      "Epoch 148/400\n",
      "177/177 [==============================] - 0s 643us/step - loss: 0.4095 - accuracy: 0.8046\n",
      "Epoch 149/400\n",
      "177/177 [==============================] - 0s 653us/step - loss: 0.4101 - accuracy: 0.8099\n",
      "Epoch 150/400\n",
      "177/177 [==============================] - 0s 656us/step - loss: 0.4092 - accuracy: 0.8066\n",
      "Epoch 151/400\n",
      "177/177 [==============================] - 0s 657us/step - loss: 0.4110 - accuracy: 0.8044\n",
      "Epoch 152/400\n",
      "177/177 [==============================] - 0s 656us/step - loss: 0.4095 - accuracy: 0.8043\n",
      "Epoch 153/400\n",
      "177/177 [==============================] - 0s 630us/step - loss: 0.4088 - accuracy: 0.8055\n",
      "Epoch 154/400\n",
      "177/177 [==============================] - 0s 644us/step - loss: 0.4157 - accuracy: 0.8035\n",
      "Epoch 155/400\n",
      "177/177 [==============================] - 0s 648us/step - loss: 0.4095 - accuracy: 0.8027\n",
      "Epoch 156/400\n",
      "177/177 [==============================] - 0s 649us/step - loss: 0.4084 - accuracy: 0.8078\n",
      "Epoch 157/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "177/177 [==============================] - 0s 645us/step - loss: 0.4078 - accuracy: 0.8043\n",
      "Epoch 158/400\n",
      "177/177 [==============================] - 0s 651us/step - loss: 0.4086 - accuracy: 0.8066\n",
      "Epoch 159/400\n",
      "177/177 [==============================] - 0s 656us/step - loss: 0.4070 - accuracy: 0.8078\n",
      "Epoch 160/400\n",
      "177/177 [==============================] - 0s 648us/step - loss: 0.4076 - accuracy: 0.8098\n",
      "Epoch 161/400\n",
      "177/177 [==============================] - 0s 647us/step - loss: 0.4119 - accuracy: 0.8028\n",
      "Epoch 162/400\n",
      "177/177 [==============================] - 0s 638us/step - loss: 0.4108 - accuracy: 0.8053\n",
      "Epoch 163/400\n",
      "177/177 [==============================] - 0s 649us/step - loss: 0.4077 - accuracy: 0.8048\n",
      "Epoch 164/400\n",
      "177/177 [==============================] - 0s 648us/step - loss: 0.4083 - accuracy: 0.8043\n",
      "Epoch 165/400\n",
      "177/177 [==============================] - 0s 647us/step - loss: 0.4077 - accuracy: 0.8067\n",
      "Epoch 166/400\n",
      "177/177 [==============================] - 0s 663us/step - loss: 0.4078 - accuracy: 0.8094\n",
      "Epoch 167/400\n",
      "177/177 [==============================] - 0s 647us/step - loss: 0.4081 - accuracy: 0.8039\n",
      "Epoch 168/400\n",
      "177/177 [==============================] - 0s 665us/step - loss: 0.4106 - accuracy: 0.8108\n",
      "Epoch 169/400\n",
      "177/177 [==============================] - 0s 667us/step - loss: 0.4089 - accuracy: 0.8053\n",
      "Epoch 170/400\n",
      "177/177 [==============================] - 0s 668us/step - loss: 0.4126 - accuracy: 0.8046\n",
      "Epoch 171/400\n",
      "177/177 [==============================] - 0s 662us/step - loss: 0.4081 - accuracy: 0.8053\n",
      "Epoch 172/400\n",
      "177/177 [==============================] - 0s 751us/step - loss: 0.4087 - accuracy: 0.8059\n",
      "Epoch 173/400\n",
      "177/177 [==============================] - 0s 708us/step - loss: 0.4107 - accuracy: 0.8055\n",
      "Epoch 174/400\n",
      "177/177 [==============================] - 0s 681us/step - loss: 0.4103 - accuracy: 0.7995\n",
      "Epoch 175/400\n",
      "177/177 [==============================] - 0s 648us/step - loss: 0.4106 - accuracy: 0.8060\n",
      "Epoch 176/400\n",
      "177/177 [==============================] - 0s 647us/step - loss: 0.4068 - accuracy: 0.8067\n",
      "Epoch 177/400\n",
      "177/177 [==============================] - 0s 649us/step - loss: 0.4083 - accuracy: 0.8067\n",
      "Epoch 178/400\n",
      "177/177 [==============================] - 0s 648us/step - loss: 0.4062 - accuracy: 0.8105\n",
      "Epoch 179/400\n",
      "177/177 [==============================] - 0s 643us/step - loss: 0.4079 - accuracy: 0.8051\n",
      "Epoch 180/400\n",
      "177/177 [==============================] - 0s 637us/step - loss: 0.4080 - accuracy: 0.8060\n",
      "Epoch 181/400\n",
      "177/177 [==============================] - 0s 645us/step - loss: 0.4075 - accuracy: 0.8071\n",
      "Epoch 182/400\n",
      "177/177 [==============================] - 0s 647us/step - loss: 0.4141 - accuracy: 0.8050\n",
      "Epoch 183/400\n",
      "177/177 [==============================] - 0s 654us/step - loss: 0.4092 - accuracy: 0.8046\n",
      "Epoch 184/400\n",
      "177/177 [==============================] - 0s 646us/step - loss: 0.4106 - accuracy: 0.8073\n",
      "Epoch 185/400\n",
      "177/177 [==============================] - 0s 649us/step - loss: 0.4089 - accuracy: 0.8073\n",
      "Epoch 186/400\n",
      "177/177 [==============================] - 0s 649us/step - loss: 0.4080 - accuracy: 0.8046\n",
      "Epoch 187/400\n",
      "177/177 [==============================] - 0s 647us/step - loss: 0.4099 - accuracy: 0.8037\n",
      "Epoch 188/400\n",
      "177/177 [==============================] - 0s 641us/step - loss: 0.4098 - accuracy: 0.8083\n",
      "Epoch 189/400\n",
      "177/177 [==============================] - 0s 638us/step - loss: 0.4077 - accuracy: 0.8044\n",
      "Epoch 190/400\n",
      "177/177 [==============================] - 0s 641us/step - loss: 0.4078 - accuracy: 0.8080\n",
      "Epoch 191/400\n",
      "177/177 [==============================] - 0s 645us/step - loss: 0.4081 - accuracy: 0.8119\n",
      "Epoch 192/400\n",
      "177/177 [==============================] - 0s 654us/step - loss: 0.4082 - accuracy: 0.8046\n",
      "Epoch 193/400\n",
      "177/177 [==============================] - 0s 637us/step - loss: 0.4072 - accuracy: 0.8105\n",
      "Epoch 194/400\n",
      "177/177 [==============================] - 0s 665us/step - loss: 0.4067 - accuracy: 0.8094\n",
      "Epoch 195/400\n",
      "177/177 [==============================] - 0s 644us/step - loss: 0.4093 - accuracy: 0.8105\n",
      "Epoch 196/400\n",
      "177/177 [==============================] - 0s 646us/step - loss: 0.4083 - accuracy: 0.8046\n",
      "Epoch 197/400\n",
      "177/177 [==============================] - 0s 640us/step - loss: 0.4078 - accuracy: 0.8053\n",
      "Epoch 198/400\n",
      "177/177 [==============================] - 0s 639us/step - loss: 0.4069 - accuracy: 0.8067\n",
      "Epoch 199/400\n",
      "177/177 [==============================] - 0s 645us/step - loss: 0.4080 - accuracy: 0.8096\n",
      "Epoch 200/400\n",
      "177/177 [==============================] - 0s 638us/step - loss: 0.4066 - accuracy: 0.8067\n",
      "Epoch 201/400\n",
      "177/177 [==============================] - 0s 660us/step - loss: 0.4090 - accuracy: 0.8069\n",
      "Epoch 202/400\n",
      "177/177 [==============================] - 0s 651us/step - loss: 0.4077 - accuracy: 0.8117\n",
      "Epoch 203/400\n",
      "177/177 [==============================] - 0s 644us/step - loss: 0.4092 - accuracy: 0.8035\n",
      "Epoch 204/400\n",
      "177/177 [==============================] - 0s 653us/step - loss: 0.4078 - accuracy: 0.8110\n",
      "Epoch 205/400\n",
      "177/177 [==============================] - 0s 674us/step - loss: 0.4079 - accuracy: 0.8082\n",
      "Epoch 206/400\n",
      "177/177 [==============================] - 0s 640us/step - loss: 0.4061 - accuracy: 0.8044\n",
      "Epoch 207/400\n",
      "177/177 [==============================] - 0s 640us/step - loss: 0.4064 - accuracy: 0.8075\n",
      "Epoch 208/400\n",
      "177/177 [==============================] - 0s 647us/step - loss: 0.4065 - accuracy: 0.8099\n",
      "Epoch 209/400\n",
      "177/177 [==============================] - 0s 639us/step - loss: 0.4055 - accuracy: 0.8092\n",
      "Epoch 210/400\n",
      "177/177 [==============================] - 0s 649us/step - loss: 0.4090 - accuracy: 0.8048\n",
      "Epoch 211/400\n",
      "177/177 [==============================] - 0s 647us/step - loss: 0.4072 - accuracy: 0.8069\n",
      "Epoch 212/400\n",
      "177/177 [==============================] - 0s 638us/step - loss: 0.4072 - accuracy: 0.8064\n",
      "Epoch 213/400\n",
      "177/177 [==============================] - 0s 655us/step - loss: 0.4070 - accuracy: 0.8082\n",
      "Epoch 214/400\n",
      "177/177 [==============================] - 0s 655us/step - loss: 0.4066 - accuracy: 0.8069\n",
      "Epoch 215/400\n",
      "177/177 [==============================] - 0s 643us/step - loss: 0.4073 - accuracy: 0.8073\n",
      "Epoch 216/400\n",
      "177/177 [==============================] - 0s 651us/step - loss: 0.4057 - accuracy: 0.8073\n",
      "Epoch 217/400\n",
      "177/177 [==============================] - 0s 638us/step - loss: 0.4078 - accuracy: 0.8078\n",
      "Epoch 218/400\n",
      "177/177 [==============================] - 0s 666us/step - loss: 0.4081 - accuracy: 0.8067\n",
      "Epoch 219/400\n",
      "177/177 [==============================] - 0s 675us/step - loss: 0.4064 - accuracy: 0.8059\n",
      "Epoch 220/400\n",
      "177/177 [==============================] - 0s 661us/step - loss: 0.4064 - accuracy: 0.8076\n",
      "Epoch 221/400\n",
      "177/177 [==============================] - 0s 648us/step - loss: 0.4070 - accuracy: 0.8098\n",
      "Epoch 222/400\n",
      "177/177 [==============================] - 0s 651us/step - loss: 0.4075 - accuracy: 0.8085\n",
      "Epoch 223/400\n",
      "177/177 [==============================] - 0s 651us/step - loss: 0.4050 - accuracy: 0.8021\n",
      "Epoch 224/400\n",
      "177/177 [==============================] - 0s 672us/step - loss: 0.4068 - accuracy: 0.8083\n",
      "Epoch 225/400\n",
      "177/177 [==============================] - 0s 639us/step - loss: 0.4062 - accuracy: 0.8083\n",
      "Epoch 226/400\n",
      "177/177 [==============================] - 0s 647us/step - loss: 0.4076 - accuracy: 0.8098\n",
      "Epoch 227/400\n",
      "177/177 [==============================] - 0s 657us/step - loss: 0.4053 - accuracy: 0.8069\n",
      "Epoch 228/400\n",
      "177/177 [==============================] - 0s 656us/step - loss: 0.4091 - accuracy: 0.8051\n",
      "Epoch 229/400\n",
      "177/177 [==============================] - 0s 644us/step - loss: 0.4056 - accuracy: 0.8099\n",
      "Epoch 230/400\n",
      "177/177 [==============================] - 0s 643us/step - loss: 0.4074 - accuracy: 0.8059\n",
      "Epoch 231/400\n",
      "177/177 [==============================] - 0s 647us/step - loss: 0.4079 - accuracy: 0.8101\n",
      "Epoch 232/400\n",
      "177/177 [==============================] - 0s 650us/step - loss: 0.4074 - accuracy: 0.8087\n",
      "Epoch 233/400\n",
      "177/177 [==============================] - 0s 645us/step - loss: 0.4060 - accuracy: 0.8085\n",
      "Epoch 234/400\n",
      "177/177 [==============================] - 0s 638us/step - loss: 0.4045 - accuracy: 0.8067\n",
      "Epoch 235/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "177/177 [==============================] - 0s 646us/step - loss: 0.4070 - accuracy: 0.8048\n",
      "Epoch 236/400\n",
      "177/177 [==============================] - 0s 653us/step - loss: 0.4057 - accuracy: 0.8043\n",
      "Epoch 237/400\n",
      "177/177 [==============================] - 0s 649us/step - loss: 0.4082 - accuracy: 0.8067\n",
      "Epoch 238/400\n",
      "177/177 [==============================] - 0s 649us/step - loss: 0.4087 - accuracy: 0.8067\n",
      "Epoch 239/400\n",
      "177/177 [==============================] - 0s 653us/step - loss: 0.4070 - accuracy: 0.8050\n",
      "Epoch 240/400\n",
      "177/177 [==============================] - 0s 651us/step - loss: 0.4115 - accuracy: 0.8028\n",
      "Epoch 241/400\n",
      "177/177 [==============================] - 0s 653us/step - loss: 0.4091 - accuracy: 0.8035\n",
      "Epoch 242/400\n",
      "177/177 [==============================] - 0s 647us/step - loss: 0.4058 - accuracy: 0.8062\n",
      "Epoch 243/400\n",
      "177/177 [==============================] - 0s 631us/step - loss: 0.4073 - accuracy: 0.8057\n",
      "Epoch 244/400\n",
      "177/177 [==============================] - 0s 651us/step - loss: 0.4079 - accuracy: 0.8051\n",
      "Epoch 245/400\n",
      "177/177 [==============================] - 0s 650us/step - loss: 0.4089 - accuracy: 0.8071\n",
      "Epoch 246/400\n",
      "177/177 [==============================] - 0s 649us/step - loss: 0.4058 - accuracy: 0.8062\n",
      "Epoch 247/400\n",
      "177/177 [==============================] - 0s 652us/step - loss: 0.4069 - accuracy: 0.8050\n",
      "Epoch 248/400\n",
      "177/177 [==============================] - 0s 651us/step - loss: 0.4057 - accuracy: 0.8080\n",
      "Epoch 249/400\n",
      "177/177 [==============================] - 0s 648us/step - loss: 0.4069 - accuracy: 0.8060\n",
      "Epoch 250/400\n",
      "177/177 [==============================] - 0s 651us/step - loss: 0.4085 - accuracy: 0.8062\n",
      "Epoch 251/400\n",
      "177/177 [==============================] - 0s 650us/step - loss: 0.4042 - accuracy: 0.8085\n",
      "Epoch 252/400\n",
      "177/177 [==============================] - 0s 632us/step - loss: 0.4069 - accuracy: 0.8082\n",
      "Epoch 253/400\n",
      "177/177 [==============================] - 0s 656us/step - loss: 0.4040 - accuracy: 0.8106\n",
      "Epoch 254/400\n",
      "177/177 [==============================] - 0s 658us/step - loss: 0.4111 - accuracy: 0.8050\n",
      "Epoch 255/400\n",
      "177/177 [==============================] - 0s 647us/step - loss: 0.4073 - accuracy: 0.8066\n",
      "Epoch 256/400\n",
      "177/177 [==============================] - 0s 652us/step - loss: 0.4069 - accuracy: 0.8023\n",
      "Epoch 257/400\n",
      "177/177 [==============================] - 0s 648us/step - loss: 0.4090 - accuracy: 0.8035\n",
      "Epoch 258/400\n",
      "177/177 [==============================] - 0s 663us/step - loss: 0.4072 - accuracy: 0.8039\n",
      "Epoch 259/400\n",
      "177/177 [==============================] - 0s 646us/step - loss: 0.4066 - accuracy: 0.8083\n",
      "Epoch 260/400\n",
      "177/177 [==============================] - 0s 669us/step - loss: 0.4070 - accuracy: 0.8071\n",
      "Epoch 261/400\n",
      "177/177 [==============================] - 0s 643us/step - loss: 0.4063 - accuracy: 0.8075\n",
      "Epoch 262/400\n",
      "177/177 [==============================] - 0s 663us/step - loss: 0.4067 - accuracy: 0.8066\n",
      "Epoch 263/400\n",
      "177/177 [==============================] - 0s 654us/step - loss: 0.4064 - accuracy: 0.8071\n",
      "Epoch 264/400\n",
      "177/177 [==============================] - 0s 656us/step - loss: 0.4053 - accuracy: 0.8080\n",
      "Epoch 265/400\n",
      "177/177 [==============================] - 0s 660us/step - loss: 0.4097 - accuracy: 0.8082\n",
      "Epoch 266/400\n",
      "177/177 [==============================] - 0s 655us/step - loss: 0.4072 - accuracy: 0.8064\n",
      "Epoch 267/400\n",
      "177/177 [==============================] - 0s 661us/step - loss: 0.4073 - accuracy: 0.8069\n",
      "Epoch 268/400\n",
      "177/177 [==============================] - 0s 652us/step - loss: 0.4061 - accuracy: 0.8101\n",
      "Epoch 269/400\n",
      "177/177 [==============================] - 0s 651us/step - loss: 0.4046 - accuracy: 0.8050\n",
      "Epoch 270/400\n",
      "177/177 [==============================] - 0s 639us/step - loss: 0.4058 - accuracy: 0.8083\n",
      "Epoch 271/400\n",
      "177/177 [==============================] - 0s 648us/step - loss: 0.4074 - accuracy: 0.8076\n",
      "Epoch 272/400\n",
      "177/177 [==============================] - 0s 651us/step - loss: 0.4059 - accuracy: 0.8076\n",
      "Epoch 273/400\n",
      "177/177 [==============================] - 0s 669us/step - loss: 0.4048 - accuracy: 0.8080\n",
      "Epoch 274/400\n",
      "177/177 [==============================] - 0s 654us/step - loss: 0.4042 - accuracy: 0.8067\n",
      "Epoch 275/400\n",
      "177/177 [==============================] - 0s 642us/step - loss: 0.4065 - accuracy: 0.8098\n",
      "Epoch 276/400\n",
      "177/177 [==============================] - 0s 661us/step - loss: 0.4058 - accuracy: 0.8053\n",
      "Epoch 277/400\n",
      "177/177 [==============================] - 0s 653us/step - loss: 0.4074 - accuracy: 0.8099\n",
      "Epoch 278/400\n",
      "177/177 [==============================] - 0s 651us/step - loss: 0.4062 - accuracy: 0.8050\n",
      "Epoch 279/400\n",
      "177/177 [==============================] - 0s 639us/step - loss: 0.4052 - accuracy: 0.8076\n",
      "Epoch 280/400\n",
      "177/177 [==============================] - 0s 664us/step - loss: 0.4062 - accuracy: 0.8087\n",
      "Epoch 281/400\n",
      "177/177 [==============================] - 0s 675us/step - loss: 0.4060 - accuracy: 0.8101\n",
      "Epoch 282/400\n",
      "177/177 [==============================] - 0s 665us/step - loss: 0.4065 - accuracy: 0.8060\n",
      "Epoch 283/400\n",
      "177/177 [==============================] - 0s 647us/step - loss: 0.4052 - accuracy: 0.8087\n",
      "Epoch 284/400\n",
      "177/177 [==============================] - 0s 662us/step - loss: 0.4066 - accuracy: 0.8091\n",
      "Epoch 285/400\n",
      "177/177 [==============================] - 0s 661us/step - loss: 0.4069 - accuracy: 0.8037\n",
      "Epoch 286/400\n",
      "177/177 [==============================] - 0s 657us/step - loss: 0.4063 - accuracy: 0.8082\n",
      "Epoch 287/400\n",
      "177/177 [==============================] - 0s 692us/step - loss: 0.4057 - accuracy: 0.8082\n",
      "Epoch 288/400\n",
      "177/177 [==============================] - 0s 642us/step - loss: 0.4052 - accuracy: 0.8080\n",
      "Epoch 289/400\n",
      "177/177 [==============================] - 0s 650us/step - loss: 0.4058 - accuracy: 0.8067\n",
      "Epoch 290/400\n",
      "177/177 [==============================] - 0s 680us/step - loss: 0.4047 - accuracy: 0.8082\n",
      "Epoch 291/400\n",
      "177/177 [==============================] - 0s 656us/step - loss: 0.4092 - accuracy: 0.8091\n",
      "Epoch 292/400\n",
      "177/177 [==============================] - 0s 677us/step - loss: 0.4066 - accuracy: 0.8098\n",
      "Epoch 293/400\n",
      "177/177 [==============================] - 0s 694us/step - loss: 0.4035 - accuracy: 0.8041\n",
      "Epoch 294/400\n",
      "177/177 [==============================] - 0s 648us/step - loss: 0.4069 - accuracy: 0.8096\n",
      "Epoch 295/400\n",
      "177/177 [==============================] - 0s 674us/step - loss: 0.4053 - accuracy: 0.8098\n",
      "Epoch 296/400\n",
      "177/177 [==============================] - 0s 667us/step - loss: 0.4067 - accuracy: 0.8055\n",
      "Epoch 297/400\n",
      "177/177 [==============================] - 0s 648us/step - loss: 0.4060 - accuracy: 0.8071\n",
      "Epoch 298/400\n",
      "177/177 [==============================] - 0s 686us/step - loss: 0.4062 - accuracy: 0.8092\n",
      "Epoch 299/400\n",
      "177/177 [==============================] - 0s 659us/step - loss: 0.4050 - accuracy: 0.8075\n",
      "Epoch 300/400\n",
      "177/177 [==============================] - 0s 650us/step - loss: 0.4053 - accuracy: 0.8025\n",
      "Epoch 301/400\n",
      "177/177 [==============================] - 0s 656us/step - loss: 0.4047 - accuracy: 0.8057\n",
      "Epoch 302/400\n",
      "177/177 [==============================] - 0s 666us/step - loss: 0.4053 - accuracy: 0.8062\n",
      "Epoch 303/400\n",
      "177/177 [==============================] - 0s 663us/step - loss: 0.4037 - accuracy: 0.8073\n",
      "Epoch 304/400\n",
      "177/177 [==============================] - 0s 683us/step - loss: 0.4062 - accuracy: 0.8048\n",
      "Epoch 305/400\n",
      "177/177 [==============================] - 0s 711us/step - loss: 0.4051 - accuracy: 0.8101\n",
      "Epoch 306/400\n",
      "177/177 [==============================] - 0s 786us/step - loss: 0.4074 - accuracy: 0.8060\n",
      "Epoch 307/400\n",
      "177/177 [==============================] - 0s 740us/step - loss: 0.4043 - accuracy: 0.8098\n",
      "Epoch 308/400\n",
      "177/177 [==============================] - 0s 799us/step - loss: 0.4042 - accuracy: 0.8073\n",
      "Epoch 309/400\n",
      "177/177 [==============================] - 0s 770us/step - loss: 0.4052 - accuracy: 0.8050\n",
      "Epoch 310/400\n",
      "177/177 [==============================] - 0s 664us/step - loss: 0.4066 - accuracy: 0.8057\n",
      "Epoch 311/400\n",
      "177/177 [==============================] - 0s 682us/step - loss: 0.4060 - accuracy: 0.8092\n",
      "Epoch 312/400\n",
      "177/177 [==============================] - 0s 671us/step - loss: 0.4031 - accuracy: 0.8082\n",
      "Epoch 313/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "177/177 [==============================] - 0s 660us/step - loss: 0.4028 - accuracy: 0.8092\n",
      "Epoch 314/400\n",
      "177/177 [==============================] - 0s 674us/step - loss: 0.4070 - accuracy: 0.8046\n",
      "Epoch 315/400\n",
      "177/177 [==============================] - 0s 654us/step - loss: 0.4069 - accuracy: 0.8051\n",
      "Epoch 316/400\n",
      "177/177 [==============================] - 0s 645us/step - loss: 0.4052 - accuracy: 0.8075\n",
      "Epoch 317/400\n",
      "177/177 [==============================] - 0s 664us/step - loss: 0.4040 - accuracy: 0.8051\n",
      "Epoch 318/400\n",
      "177/177 [==============================] - 0s 658us/step - loss: 0.4045 - accuracy: 0.8067\n",
      "Epoch 319/400\n",
      "177/177 [==============================] - 0s 679us/step - loss: 0.4044 - accuracy: 0.8062\n",
      "Epoch 320/400\n",
      "177/177 [==============================] - 0s 663us/step - loss: 0.4047 - accuracy: 0.8071\n",
      "Epoch 321/400\n",
      "177/177 [==============================] - 0s 662us/step - loss: 0.4051 - accuracy: 0.8076\n",
      "Epoch 322/400\n",
      "177/177 [==============================] - 0s 657us/step - loss: 0.4072 - accuracy: 0.8051\n",
      "Epoch 323/400\n",
      "177/177 [==============================] - 0s 662us/step - loss: 0.4044 - accuracy: 0.8112\n",
      "Epoch 324/400\n",
      "177/177 [==============================] - 0s 645us/step - loss: 0.4049 - accuracy: 0.8101\n",
      "Epoch 325/400\n",
      "177/177 [==============================] - 0s 666us/step - loss: 0.4055 - accuracy: 0.8055\n",
      "Epoch 326/400\n",
      "177/177 [==============================] - 0s 654us/step - loss: 0.4058 - accuracy: 0.8066\n",
      "Epoch 327/400\n",
      "177/177 [==============================] - 0s 643us/step - loss: 0.4032 - accuracy: 0.8112\n",
      "Epoch 328/400\n",
      "177/177 [==============================] - 0s 658us/step - loss: 0.4053 - accuracy: 0.8078\n",
      "Epoch 329/400\n",
      "177/177 [==============================] - 0s 645us/step - loss: 0.4047 - accuracy: 0.8059\n",
      "Epoch 330/400\n",
      "177/177 [==============================] - 0s 654us/step - loss: 0.4033 - accuracy: 0.8078\n",
      "Epoch 331/400\n",
      "177/177 [==============================] - 0s 648us/step - loss: 0.4073 - accuracy: 0.8098\n",
      "Epoch 332/400\n",
      "177/177 [==============================] - 0s 656us/step - loss: 0.4049 - accuracy: 0.8089\n",
      "Epoch 333/400\n",
      "177/177 [==============================] - 0s 655us/step - loss: 0.4061 - accuracy: 0.8087\n",
      "Epoch 334/400\n",
      "177/177 [==============================] - 0s 654us/step - loss: 0.4057 - accuracy: 0.8059\n",
      "Epoch 335/400\n",
      "177/177 [==============================] - 0s 654us/step - loss: 0.4051 - accuracy: 0.8101\n",
      "Epoch 336/400\n",
      "177/177 [==============================] - 0s 649us/step - loss: 0.4029 - accuracy: 0.8135\n",
      "Epoch 337/400\n",
      "177/177 [==============================] - 0s 645us/step - loss: 0.4079 - accuracy: 0.8048\n",
      "Epoch 338/400\n",
      "177/177 [==============================] - 0s 661us/step - loss: 0.4058 - accuracy: 0.8064\n",
      "Epoch 339/400\n",
      "177/177 [==============================] - 0s 646us/step - loss: 0.4057 - accuracy: 0.8073\n",
      "Epoch 340/400\n",
      "177/177 [==============================] - 0s 649us/step - loss: 0.4049 - accuracy: 0.8096\n",
      "Epoch 341/400\n",
      "177/177 [==============================] - 0s 658us/step - loss: 0.4057 - accuracy: 0.8128\n",
      "Epoch 342/400\n",
      "177/177 [==============================] - 0s 648us/step - loss: 0.4039 - accuracy: 0.8101\n",
      "Epoch 343/400\n",
      "177/177 [==============================] - 0s 660us/step - loss: 0.4067 - accuracy: 0.8087\n",
      "Epoch 344/400\n",
      "177/177 [==============================] - 0s 657us/step - loss: 0.4062 - accuracy: 0.8106\n",
      "Epoch 345/400\n",
      "177/177 [==============================] - 0s 649us/step - loss: 0.4053 - accuracy: 0.8094\n",
      "Epoch 346/400\n",
      "177/177 [==============================] - 0s 670us/step - loss: 0.4055 - accuracy: 0.8075\n",
      "Epoch 347/400\n",
      "177/177 [==============================] - 0s 649us/step - loss: 0.4062 - accuracy: 0.8053\n",
      "Epoch 348/400\n",
      "177/177 [==============================] - 0s 648us/step - loss: 0.4049 - accuracy: 0.8080\n",
      "Epoch 349/400\n",
      "177/177 [==============================] - 0s 635us/step - loss: 0.4067 - accuracy: 0.8053\n",
      "Epoch 350/400\n",
      "177/177 [==============================] - 0s 657us/step - loss: 0.4047 - accuracy: 0.8091\n",
      "Epoch 351/400\n",
      "177/177 [==============================] - 0s 664us/step - loss: 0.4059 - accuracy: 0.8035\n",
      "Epoch 352/400\n",
      "177/177 [==============================] - 0s 647us/step - loss: 0.4085 - accuracy: 0.8080\n",
      "Epoch 353/400\n",
      "177/177 [==============================] - 0s 664us/step - loss: 0.4057 - accuracy: 0.8085\n",
      "Epoch 354/400\n",
      "177/177 [==============================] - 0s 650us/step - loss: 0.4051 - accuracy: 0.8078\n",
      "Epoch 355/400\n",
      "177/177 [==============================] - 0s 650us/step - loss: 0.4052 - accuracy: 0.8101\n",
      "Epoch 356/400\n",
      "177/177 [==============================] - 0s 648us/step - loss: 0.4049 - accuracy: 0.8030\n",
      "Epoch 357/400\n",
      "177/177 [==============================] - 0s 657us/step - loss: 0.4041 - accuracy: 0.8083\n",
      "Epoch 358/400\n",
      "177/177 [==============================] - 0s 639us/step - loss: 0.4033 - accuracy: 0.8075\n",
      "Epoch 359/400\n",
      "177/177 [==============================] - 0s 649us/step - loss: 0.4054 - accuracy: 0.8083\n",
      "Epoch 360/400\n",
      "177/177 [==============================] - 0s 657us/step - loss: 0.4047 - accuracy: 0.8073\n",
      "Epoch 361/400\n",
      "177/177 [==============================] - 0s 650us/step - loss: 0.4055 - accuracy: 0.8037\n",
      "Epoch 362/400\n",
      "177/177 [==============================] - 0s 651us/step - loss: 0.4051 - accuracy: 0.8067\n",
      "Epoch 363/400\n",
      "177/177 [==============================] - 0s 652us/step - loss: 0.4027 - accuracy: 0.8121\n",
      "Epoch 364/400\n",
      "177/177 [==============================] - 0s 654us/step - loss: 0.4041 - accuracy: 0.8073\n",
      "Epoch 365/400\n",
      "177/177 [==============================] - 0s 654us/step - loss: 0.4049 - accuracy: 0.8080\n",
      "Epoch 366/400\n",
      "177/177 [==============================] - 0s 656us/step - loss: 0.4050 - accuracy: 0.8051\n",
      "Epoch 367/400\n",
      "177/177 [==============================] - 0s 635us/step - loss: 0.4045 - accuracy: 0.8117\n",
      "Epoch 368/400\n",
      "177/177 [==============================] - 0s 654us/step - loss: 0.4018 - accuracy: 0.8115\n",
      "Epoch 369/400\n",
      "177/177 [==============================] - 0s 653us/step - loss: 0.4043 - accuracy: 0.8085\n",
      "Epoch 370/400\n",
      "177/177 [==============================] - 0s 647us/step - loss: 0.4051 - accuracy: 0.8030\n",
      "Epoch 371/400\n",
      "177/177 [==============================] - 0s 655us/step - loss: 0.4033 - accuracy: 0.8135\n",
      "Epoch 372/400\n",
      "177/177 [==============================] - 0s 642us/step - loss: 0.4035 - accuracy: 0.8060\n",
      "Epoch 373/400\n",
      "177/177 [==============================] - 0s 648us/step - loss: 0.4049 - accuracy: 0.8080\n",
      "Epoch 374/400\n",
      "177/177 [==============================] - 0s 648us/step - loss: 0.4045 - accuracy: 0.8087\n",
      "Epoch 375/400\n",
      "177/177 [==============================] - 0s 652us/step - loss: 0.4036 - accuracy: 0.8085\n",
      "Epoch 376/400\n",
      "177/177 [==============================] - 0s 641us/step - loss: 0.4031 - accuracy: 0.8099\n",
      "Epoch 377/400\n",
      "177/177 [==============================] - 0s 654us/step - loss: 0.4047 - accuracy: 0.8051\n",
      "Epoch 378/400\n",
      "177/177 [==============================] - 0s 647us/step - loss: 0.4064 - accuracy: 0.8055\n",
      "Epoch 379/400\n",
      "177/177 [==============================] - 0s 651us/step - loss: 0.4035 - accuracy: 0.8098\n",
      "Epoch 380/400\n",
      "177/177 [==============================] - 0s 649us/step - loss: 0.4046 - accuracy: 0.8067\n",
      "Epoch 381/400\n",
      "177/177 [==============================] - 0s 655us/step - loss: 0.4045 - accuracy: 0.8085\n",
      "Epoch 382/400\n",
      "177/177 [==============================] - 0s 649us/step - loss: 0.4041 - accuracy: 0.8069\n",
      "Epoch 383/400\n",
      "177/177 [==============================] - 0s 655us/step - loss: 0.4043 - accuracy: 0.8110\n",
      "Epoch 384/400\n",
      "177/177 [==============================] - 0s 660us/step - loss: 0.4035 - accuracy: 0.8080\n",
      "Epoch 385/400\n",
      "177/177 [==============================] - 0s 639us/step - loss: 0.4080 - accuracy: 0.8085\n",
      "Epoch 386/400\n",
      "177/177 [==============================] - 0s 656us/step - loss: 0.4058 - accuracy: 0.8057\n",
      "Epoch 387/400\n",
      "177/177 [==============================] - 0s 655us/step - loss: 0.4042 - accuracy: 0.8067\n",
      "Epoch 388/400\n",
      "177/177 [==============================] - 0s 651us/step - loss: 0.4043 - accuracy: 0.8099\n",
      "Epoch 389/400\n",
      "177/177 [==============================] - 0s 653us/step - loss: 0.4016 - accuracy: 0.8083\n",
      "Epoch 390/400\n",
      "177/177 [==============================] - 0s 658us/step - loss: 0.4039 - accuracy: 0.8050\n",
      "Epoch 391/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "177/177 [==============================] - 0s 647us/step - loss: 0.4061 - accuracy: 0.8075\n",
      "Epoch 392/400\n",
      "177/177 [==============================] - 0s 661us/step - loss: 0.4042 - accuracy: 0.8069\n",
      "Epoch 393/400\n",
      "177/177 [==============================] - 0s 655us/step - loss: 0.4047 - accuracy: 0.8071\n",
      "Epoch 394/400\n",
      "177/177 [==============================] - 0s 636us/step - loss: 0.4027 - accuracy: 0.8073\n",
      "Epoch 395/400\n",
      "177/177 [==============================] - 0s 659us/step - loss: 0.4040 - accuracy: 0.8062\n",
      "Epoch 396/400\n",
      "177/177 [==============================] - 0s 656us/step - loss: 0.4037 - accuracy: 0.8069\n",
      "Epoch 397/400\n",
      "177/177 [==============================] - 0s 662us/step - loss: 0.4060 - accuracy: 0.8083\n",
      "Epoch 398/400\n",
      "177/177 [==============================] - 0s 689us/step - loss: 0.4048 - accuracy: 0.8083\n",
      "Epoch 399/400\n",
      "177/177 [==============================] - 0s 700us/step - loss: 0.4029 - accuracy: 0.8133\n",
      "Epoch 400/400\n",
      "177/177 [==============================] - 0s 694us/step - loss: 0.4028 - accuracy: 0.8073\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x2967fbb90>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=400, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - 0s 512us/step\n"
     ]
    }
   ],
   "source": [
    "y_hat = model.predict(X_test)\n",
    "y_hat = [0 if val < 0.5 else 1 for val in y_hat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " ...]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7885024840312278"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Saving and Reloading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: tfmodel/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: tfmodel/assets\n"
     ]
    }
   ],
   "source": [
    "model.save('tfmodel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('tfmodel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
